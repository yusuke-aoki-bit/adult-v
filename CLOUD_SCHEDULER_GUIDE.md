# DUGA Image Crawler - Cloud Scheduler Deployment Guide

**Date**: 2025-11-25
**Status**: Ready for deployment
**Local Test**: âœ… 100/100 products successful

---

## ğŸ“Š Overview

### Current Status
- **Total DUGA Products**: 135,895
- **Products Missing Thumbnails**: 135,895 (100%)
- **First Batch Test**: âœ… 100/100 successful (offset 0-100)

### Execution Strategy
- **Local Sequential**: ~38 hours (1359 batches Ã— 100 seconds/batch)
- **Cloud Parallel (10 jobs)**: ~4 hours (136 batches/job Ã— 100 seconds/batch)

---

## ğŸ¯ Deployment Options

### Option 1: Continue Local Execution (Simple)

Run the batch script that handles all 1,359 batches sequentially:

```bash
cd C:\Users\yuuku\cursor\adult-v
bash scripts/run-duga-batches.sh
```

**Pros:**
- Simple, no cloud setup required
- Already tested and working
- Can resume from any batch if interrupted

**Cons:**
- Takes ~38 hours
- Requires keeping local machine running
- Single point of failure

### Option 2: Cloud Scheduler Parallel Execution (Recommended)

Deploy to Cloud Run Jobs with Cloud Scheduler for parallel processing:

#### Step 1: Build and Deploy Docker Image

```bash
cd C:\Users\yuuku\cursor\adult-v

# Build image
docker build -f Dockerfile.crawler -t gcr.io/adult-v/duga-image-crawler:latest .

# Push to GCR
docker push gcr.io/adult-v/duga-image-crawler:latest
```

#### Step 2: Create Cloud Run Job

```bash
gcloud run jobs create duga-image-crawler \
  --image=gcr.io/adult-v/duga-image-crawler:latest \
  --region=asia-northeast1 \
  --service-account=crawler-service@adult-v.iam.gserviceaccount.com \
  --set-env-vars="DATABASE_URL=postgresql://adult-v:AdultV2024!Secure@34.27.234.120:5432/postgres" \
  --task-timeout=3600 \
  --max-retries=3 \
  --memory=512Mi \
  --cpu=1
```

#### Step 3: Test Single Execution

```bash
# Test with 10 products
gcloud run jobs execute duga-image-crawler \
  --region=asia-northeast1 \
  --args="--limit=10,--offset=0"

# Check execution status
gcloud run jobs executions list \
  --job=duga-image-crawler \
  --region=asia-northeast1 \
  --limit=5
```

#### Step 4: Create Parallel Cloud Schedulers

```bash
cd C:\Users\yuuku\cursor\adult-v
bash scripts/create-parallel-schedulers.sh
```

This creates 10 scheduler jobs:
- `duga-crawler-parallel-0` (offset 0)
- `duga-crawler-parallel-1` (offset 100)
- `duga-crawler-parallel-2` (offset 200)
- ...
- `duga-crawler-parallel-9` (offset 900)

Each scheduler triggers every 3 minutes and processes its assigned range.

#### Step 5: Start Parallel Execution

```bash
# Resume all schedulers
for i in {0..9}; do
  gcloud scheduler jobs resume duga-crawler-parallel-${i} --location=asia-northeast1
done
```

#### Step 6: Monitor Progress

```bash
# View recent executions
gcloud run jobs executions list \
  --job=duga-image-crawler \
  --region=asia-northeast1 \
  --limit=20

# Check specific execution logs
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=duga-image-crawler" \
  --limit=50 \
  --format=json
```

#### Step 7: Stop Execution (if needed)

```bash
# Pause all schedulers
for i in {0..9}; do
  gcloud scheduler jobs pause duga-crawler-parallel-${i} --location=asia-northeast1
done
```

#### Step 8: Cleanup After Completion

```bash
# Delete schedulers
for i in {0..9}; do
  gcloud scheduler jobs delete duga-crawler-parallel-${i} --location=asia-northeast1 --quiet
done

# Optionally delete the job
gcloud run jobs delete duga-image-crawler --region=asia-northeast1 --quiet
```

---

## ğŸ”§ Alternative: Manual Batch Execution

If you want more control, manually trigger batches:

```bash
# Process batches 0-99 (10,000 products)
for i in {0..99}; do
  offset=$((i * 100))
  echo "Processing batch $i (offset $offset)"

  gcloud run jobs execute duga-image-crawler \
    --region=asia-northeast1 \
    --args="--limit=100,--offset=${offset}" \
    --wait
done
```

---

## ğŸ“ˆ Progress Tracking

### Check Database Progress

```bash
PGPASSWORD='AdultV2024!Secure' psql -h 34.27.234.120 -U adult-v -d postgres -c \
  "SELECT
    COUNT(*) as total_duga,
    COUNT(default_thumbnail_url) as with_thumbnail,
    COUNT(*) - COUNT(default_thumbnail_url) as without_thumbnail,
    ROUND(100.0 * COUNT(default_thumbnail_url) / COUNT(*), 2) as coverage_percent
  FROM products p
  INNER JOIN product_sources ps ON p.id = ps.product_id
  WHERE ps.asp_name = 'DUGA';"
```

### Expected Progress

| Time Elapsed | Products Processed | Coverage | Remaining |
|--------------|-------------------|----------|-----------|
| 0h (start)   | 0                 | 0%       | 135,895   |
| 1h           | ~36,000           | 26%      | ~100,000  |
| 2h           | ~72,000           | 53%      | ~64,000   |
| 3h           | ~108,000          | 79%      | ~28,000   |
| 4h           | ~135,895          | 100%     | 0         |

---

## ğŸ¯ Recommendation

**For production:** Use **Option 2** (Cloud Scheduler Parallel Execution)

**Reasons:**
1. **10x faster**: 4 hours vs 38 hours
2. **More reliable**: Cloud Run handles retries and failures
3. **Better monitoring**: Cloud Logging and Cloud Monitoring integration
4. **Cost-effective**: Pay only for execution time (~$0.50 total)
5. **Scalable**: Easy to add more parallel workers if needed

**For testing/small batches:** Use local execution with `--limit` and `--offset` flags

---

## ğŸš¨ Important Notes

1. **Rate Limiting**: Each batch waits 1 second between products to avoid overwhelming DUGA servers
2. **Idempotency**: Script checks for existing thumbnails and skips already-processed products
3. **Resume Support**: If interrupted, can resume from any batch using `--offset`
4. **Error Handling**: Failed products are logged and can be retried separately
5. **Database Load**: 10 parallel jobs should be fine, but monitor database connections

---

## ğŸ“ Next Steps After DUGA

Once DUGA image crawling is complete:

1. **MGS Re-crawl** (7,346 products) - [Priority: Medium]
2. **Performer Name Normalization** (47,620 products) - [Priority: Low]

See [INVESTIGATION_REPORT.md](./INVESTIGATION_REPORT.md) for full details.

---

## ğŸ•·ï¸ Cron API Endpoints (Cloud Scheduler Integration)

### Available Endpoints

| Endpoint | Provider | Description |
|----------|----------|-------------|
| `/api/cron/crawl-duga` | DUGA | DUGA APIçµŒç”±ã§æ–°ç€ä½œå“ã‚’å–å¾— |
| `/api/cron/crawl-sokmil` | ã‚½ã‚¯ãƒŸãƒ« | Sokmil APIçµŒç”±ã§æ–°ç€ä½œå“ã‚’å–å¾— |
| `/api/cron/crawl-sokmil-scrape` | ã‚½ã‚¯ãƒŸãƒ« | Sokmilã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆï¼ˆAPIéšœå®³æ™‚ã®ä»£æ›¿ï¼‰ |
| `/api/cron/crawl-dti` | DTI | DTIç³»ã‚µã‚¤ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ãƒ«ï¼ˆã‚«ãƒªãƒ“ã€ä¸€æœ¬é“ã€HEYZOç­‰ï¼‰ |
| `/api/cron/crawl-mgs` | MGS | MGSå‹•ç”»ã®å•†å“ä¸€è¦§ã‹ã‚‰æ–°ç€ä½œå“ã‚’å–å¾— |
| `/api/cron/crawl-b10f` | B10F | B10F CSVçµŒç”±ã§ä½œå“ã‚’å–å¾— |
| `/api/cron/crawl-japanska` | Japanska | HTMLã‚¯ãƒ­ãƒ¼ãƒ«ã§ä½œå“ã‚’å–å¾— |
| `/api/cron/crawl-fc2` | FC2 | HTMLã‚¯ãƒ­ãƒ¼ãƒ«ã§ä½œå“ã‚’å–å¾— |
| `/api/cron/process-raw-data` | å…¨ã¦ | ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–å‡¦ç† |
| `/api/cron/normalize-performers` | å…¨ã¦ | Wikiå‡ºæ¼”è€…åå¯„ã›ï¼ˆå…¨ASPå¯¾å¿œï¼‰ |
| `/api/cron/backfill-images` | å…¨ã¦ | ã‚µãƒ ãƒã‚¤ãƒ«ãªã—å•†å“ã®ç”»åƒå–å¾— |
| `/api/cron/backfill-videos` | å…¨ã¦ | ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ãªã—å•†å“ã®å‹•ç”»å–å¾— |
| `/api/cron/cleanup` | å…¨ã¦ | é‡è¤‡ãƒã‚§ãƒƒã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— |
| `/api/cron/status` | - | ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª |

### Cloud Scheduler Setup for Parallel Crawling

#### Japanska (åé›†ç‡: 1% â†’ ç›®æ¨™: 10%+)

```bash
# Japanskaã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½œæˆï¼ˆ10ä¸¦åˆ—ï¼‰
for i in {0..9}; do
  start=$((30000 + i * 1000))
  gcloud scheduler jobs create http japanska-crawler-${i} \
    --location=asia-northeast1 \
    --schedule="*/10 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-japanska?start=${start}&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

#### FC2 (åé›†ç‡: 0.01% â†’ ç›®æ¨™: 1%+)

```bash
# FC2ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½œæˆï¼ˆ5ä¸¦åˆ—ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™è€ƒæ…®ï¼‰
for i in {0..4}; do
  page=$((1 + i * 10))
  gcloud scheduler jobs create http fc2-crawler-${i} \
    --location=asia-northeast1 \
    --schedule="*/15 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-fc2?page=${page}&endPage=$((page + 9))&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

#### DTI (42,269ä½œå“ â†’ åé›†æ‹¡å¤§)

```bash
# DTIã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½œæˆï¼ˆã‚µã‚¤ãƒˆåˆ¥ã€å„5ä¸¦åˆ—ï¼‰
# ã‚«ãƒªãƒ“ã‚¢ãƒ³ã‚³ãƒ 
for i in {0..4}; do
  gcloud scheduler jobs create http dti-caribbeancom-${i} \
    --location=asia-northeast1 \
    --schedule="*/10 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-dti?site=caribbeancom&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done

# ä¸€æœ¬é“
for i in {0..4}; do
  gcloud scheduler jobs create http dti-1pondo-${i} \
    --location=asia-northeast1 \
    --schedule="*/10 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-dti?site=1pondo&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done

# HEYZO
for i in {0..4}; do
  gcloud scheduler jobs create http dti-heyzo-${i} \
    --location=asia-northeast1 \
    --schedule="*/10 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-dti?site=heyzo&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

#### MGS (7,337ä½œå“ â†’ åé›†æ‹¡å¤§)

```bash
# MGSã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½œæˆï¼ˆ5ä¸¦åˆ—ã€ãƒšãƒ¼ã‚¸åˆ¥ï¼‰
for i in {0..4}; do
  page=$((1 + i))
  gcloud scheduler jobs create http mgs-crawler-${i} \
    --location=asia-northeast1 \
    --schedule="*/10 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-mgs?page=${page}&limit=30" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

#### ã‚½ã‚¯ãƒŸãƒ« (APIç‰ˆ + ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆ)

```bash
# Sokmil APIç‰ˆï¼ˆAPIå¾©æ—§æ™‚ç”¨ï¼‰
gcloud scheduler jobs create http sokmil-api-crawler \
  --location=asia-northeast1 \
  --schedule="0 */2 * * *" \
  --uri="https://your-app.run.app/api/cron/crawl-sokmil?limit=100" \
  --http-method=GET \
  --headers="X-Cron-Secret=${CRON_SECRET}" \
  --time-zone="Asia/Tokyo"

# Sokmil ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç‰ˆï¼ˆAPIéšœå®³æ™‚ã®ä»£æ›¿ï¼‰
for i in {0..4}; do
  page=$((1 + i))
  gcloud scheduler jobs create http sokmil-scrape-${i} \
    --location=asia-northeast1 \
    --schedule="*/10 * * * *" \
    --uri="https://your-app.run.app/api/cron/crawl-sokmil-scrape?page=${page}&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

#### å‡ºæ¼”è€…åå¯„ã›ï¼ˆWikié€£æº - å…¨ASPå¯¾å¿œï¼‰

å‡ºæ¼”è€…æƒ…å ±ãŒãªã„å•†å“ã®å“ç•ªã‚’Wikiã§æ¤œç´¢ã—ã€å‡ºæ¼”è€…æƒ…å ±ã‚’å–å¾—ãƒ»ç´ä»˜ã‘ã€‚
`/api/cron/normalize-performers` ã¯ `asp` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å¯¾è±¡ASPã‚’æŒ‡å®šå¯èƒ½ã€‚

```bash
# å…¨ASPç”¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½œæˆï¼ˆASPæ¯ã«5ä¸¦åˆ—ã€å„50ä»¶ï¼‰
# å¯¾å¿œASP: DUGA, MGS, DTI, b10f, Sokmil, Japanska, FC2

for asp in DUGA MGS DTI Sokmil; do
  for i in {0..4}; do
    offset=$((i * 50))
    gcloud scheduler jobs create http normalize-performers-${asp,,}-${i} \
      --location=asia-northeast1 \
      --schedule="*/15 * * * *" \
      --uri="https://your-app.run.app/api/cron/normalize-performers?asp=${asp}&limit=50&offset=${offset}" \
      --http-method=GET \
      --headers="X-Cron-Secret=${CRON_SECRET}" \
      --time-zone="Asia/Tokyo"
  done
done

# å…¨ASPä¸€æ‹¬å‡¦ç†ï¼ˆaspãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—ï¼‰
gcloud scheduler jobs create http normalize-performers-all \
  --location=asia-northeast1 \
  --schedule="0 */4 * * *" \
  --uri="https://your-app.run.app/api/cron/normalize-performers?limit=100" \
  --http-method=GET \
  --headers="X-Cron-Secret=${CRON_SECRET}" \
  --time-zone="Asia/Tokyo"
```

**åå¯„ã›å¯¾è±¡ï¼ˆWikiæ¤œç´¢ã§å“ç•ªãŒè¦‹ã¤ã‹ã‚‹ASPï¼‰:**
| ASP | æœªæ•´ç†ä»¶æ•° | åå¯„ã›æˆåŠŸè¦‹è¾¼ã¿ | å‚™è€ƒ |
|-----|-----------|----------------|------|
| MGS | 4,510 | 90%+ | æ¨™æº–å“ç•ªå½¢å¼ï¼ˆABC-123ï¼‰|
| DUGA | 19,003 | 70%+ | æ¨™æº–å“ç•ªå½¢å¼ï¼ˆABC-123ï¼‰|
| Sokmil | æœªè¨ˆæ¸¬ | 80%+ | æ¨™æº–å“ç•ªå½¢å¼ï¼ˆABC-123ï¼‰|
| DTI | 32,775 | 30%æœªæº€ | å†…éƒ¨å“ç•ªå½¢å¼ï¼ˆ123456_789ï¼‰|
| b10f | 15,459 | 0% | å†…éƒ¨IDå½¢å¼ï¼ˆ52134ï¼‰|

â€» DTI/b10fã¯å“ç•ªå½¢å¼ãŒWikiæ¤œç´¢ã«é©ã•ãªã„ãŸã‚ã€åˆ¥é€”ã‚¯ãƒ­ãƒ¼ãƒ«ã§ã®å‡ºæ¼”è€…å–å¾—ã‚’æ¨å¥¨

### Query Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `limit` | å‡¦ç†ã™ã‚‹ä½œå“æ•°ä¸Šé™ | 50-100 |
| `offset` / `start` | é–‹å§‹ä½ç½®ï¼ˆID or ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰| 0 |
| `page` | ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆFC2ç”¨ï¼‰| 1 |
| `endPage` | çµ‚äº†ãƒšãƒ¼ã‚¸ï¼ˆFC2ç”¨ï¼‰| 5 |

### Authentication

```bash
# ç’°å¢ƒå¤‰æ•°ã«è¨­å®š
export CRON_SECRET="your-secure-secret-key"

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹
curl -X GET "https://your-app.run.app/api/cron/crawl-japanska?start=34000&limit=10" \
  -H "X-Cron-Secret: ${CRON_SECRET}"
```

### åé›†ç‡ç›®æ¨™

| Provider | ç¾åœ¨ | æ¨å®šç·æ•° | ç›®æ¨™åé›†æ•° | ç›®æ¨™ç‡ |
|----------|------|----------|-----------|--------|
| DUGA | 10% | 500,000 | 100,000 | 20% |
| MGS | 7% | 100,000 | 30,000 | 30% |
| Japanska | 1% | 40,000 | 10,000 | 25% |
| FC2 | 0.01% | 1,000,000 | 10,000 | 1% |
| ã‚½ã‚¯ãƒŸãƒ« | 0% | 200,000 | 20,000 | 10% |

---

## ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ç”¨API

### ç”»åƒãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«

ã‚µãƒ ãƒã‚¤ãƒ«ãªã—å•†å“ã®ç”»åƒã‚’å–å¾—:

```bash
# MGSã®ç”»åƒã‚’50ä»¶ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«
curl -X GET "https://your-app.run.app/api/cron/backfill-images?limit=50&asp=MGS" \
  -H "X-Cron-Secret: ${CRON_SECRET}"

# å…¨ASPå¯¾è±¡
curl -X GET "https://your-app.run.app/api/cron/backfill-images?limit=100" \
  -H "X-Cron-Secret: ${CRON_SECRET}"
```

Cloud Schedulerè¨­å®š:

```bash
# ç”»åƒãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼ˆæ¯æ™‚ã€ASPåˆ¥ï¼‰
for asp in MGS DUGA SOKMIL; do
  gcloud scheduler jobs create http backfill-images-${asp,,} \
    --location=asia-northeast1 \
    --schedule="0 * * * *" \
    --uri="https://your-app.run.app/api/cron/backfill-images?asp=${asp}&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

### å‹•ç”»ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«

ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ãªã—å•†å“ã®å‹•ç”»URLã‚’å–å¾—:

```bash
# MGSã®å‹•ç”»ã‚’50ä»¶ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«
curl -X GET "https://your-app.run.app/api/cron/backfill-videos?limit=50&asp=MGS" \
  -H "X-Cron-Secret: ${CRON_SECRET}"

# å…¨ASPå¯¾è±¡
curl -X GET "https://your-app.run.app/api/cron/backfill-videos?limit=100" \
  -H "X-Cron-Secret: ${CRON_SECRET}"
```

Cloud Schedulerè¨­å®š:

```bash
# å‹•ç”»ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼ˆæ¯æ™‚ã€ASPåˆ¥ï¼‰
for asp in MGS DUGA SOKMIL; do
  gcloud scheduler jobs create http backfill-videos-${asp,,} \
    --location=asia-northeast1 \
    --schedule="30 * * * *" \
    --uri="https://your-app.run.app/api/cron/backfill-videos?asp=${asp}&limit=50" \
    --http-method=GET \
    --headers="X-Cron-Secret=${CRON_SECRET}" \
    --time-zone="Asia/Tokyo"
done
```

### ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤:

```bash
# ãƒã‚§ãƒƒã‚¯ã®ã¿ï¼ˆä¿®æ­£ãªã—ï¼‰
curl -X GET "https://your-app.run.app/api/cron/cleanup?action=check" \
  -H "X-Cron-Secret: ${CRON_SECRET}"

# é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ã¿
curl -X GET "https://your-app.run.app/api/cron/cleanup?action=check&type=duplicates" \
  -H "X-Cron-Secret: ${CRON_SECRET}"

# å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ã®ã¿
curl -X GET "https://your-app.run.app/api/cron/cleanup?action=check&type=orphans" \
  -H "X-Cron-Secret: ${CRON_SECRET}"

# å•é¡Œã‚’ä¿®æ­£
curl -X GET "https://your-app.run.app/api/cron/cleanup?action=fix" \
  -H "X-Cron-Secret: ${CRON_SECRET}"
```

Cloud Schedulerè¨­å®š:

```bash
# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæ¯æ—¥æ·±å¤œ3æ™‚ã€ãƒã‚§ãƒƒã‚¯ã®ã¿ï¼‰
gcloud scheduler jobs create http cleanup-check \
  --location=asia-northeast1 \
  --schedule="0 3 * * *" \
  --uri="https://your-app.run.app/api/cron/cleanup?action=check" \
  --http-method=GET \
  --headers="X-Cron-Secret=${CRON_SECRET}" \
  --time-zone="Asia/Tokyo"

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæ¯é€±æ—¥æ›œæ·±å¤œ4æ™‚ã€ä¿®æ­£å®Ÿè¡Œï¼‰
gcloud scheduler jobs create http cleanup-fix \
  --location=asia-northeast1 \
  --schedule="0 4 * * 0" \
  --uri="https://your-app.run.app/api/cron/cleanup?action=fix" \
  --http-method=GET \
  --headers="X-Cron-Secret=${CRON_SECRET}" \
  --time-zone="Asia/Tokyo"
```

#### ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡

| ç¨®é¡ | èª¬æ˜ | action=fixæ™‚ã®å‹•ä½œ |
|------|------|-------------------|
| é‡è¤‡å•†å“ | åŒä¸€normalized_product_idã§è¤‡æ•°ãƒ¬ã‚³ãƒ¼ãƒ‰ | æœ€æ–°ã‚’æ®‹ã—ã¦å‰Šé™¤ |
| é‡è¤‡å‡ºæ¼”è€… | åŒä¸€åã§è¤‡æ•°ãƒ¬ã‚³ãƒ¼ãƒ‰ | æœ€å°IDã«çµ±åˆ |
| å­¤ç«‹product_sources | å­˜åœ¨ã—ãªã„product_idã‚’å‚ç…§ | å‰Šé™¤ |
| å­¤ç«‹product_videos | å­˜åœ¨ã—ãªã„product_idã‚’å‚ç…§ | å‰Šé™¤ |
| å­¤ç«‹product_performers | å­˜åœ¨ã—ãªã„å‚ç…§ | å‰Šé™¤ |
| ã‚¿ã‚¤ãƒˆãƒ«ãªã—å•†å“ | titleãŒNULLã¾ãŸã¯ç©º | å‰Šé™¤ |
