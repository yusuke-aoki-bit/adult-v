# Crawler Utilities

ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

## æ¦‚è¦

ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€å„ç¨®ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã§å…±é€šã—ã¦ä½¿ç”¨ã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š

- **ãƒªãƒˆãƒ©ã‚¤å‡¦ç†** - ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
- **ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†** - ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç®¡ç†
- **ãƒ¬ãƒ¼ãƒˆåˆ¶é™** - API/ã‚µã‚¤ãƒˆã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé »åº¦åˆ¶å¾¡
- **AIæ©Ÿèƒ½** - ã‚¿ã‚°æŠ½å‡ºã€ç¿»è¨³ã€èª¬æ˜æ–‡ç”Ÿæˆ
- **é‡è¤‡é˜²æ­¢** - ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨productsã®ç´ä»˜ã‘ç®¡ç†

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```typescript
import {
  // ãƒªãƒˆãƒ©ã‚¤
  withRetry,
  fetchWithRetry,

  // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  fetchWithTimeout,
  TimeoutError,

  // ãƒ¬ãƒ¼ãƒˆåˆ¶é™
  RateLimiter,
  getRateLimiterForSite,

  // AIæ©Ÿèƒ½
  CrawlerAIHelper,
  processProductWithAI,

  // é‡è¤‡é˜²æ­¢
  checkDugaRawData,
  upsertDugaRawData,
  linkProductToRawData,
  markRawDataAsProcessed,

  // çµ±åˆfetch
  robustFetch,

  // ãƒ­ã‚°
  crawlerLog,
} from '../lib/crawler';
```

## ä½¿ã„æ–¹

### 1. å …ç‰¢ãªfetchï¼ˆæ¨å¥¨ï¼‰

```typescript
import { robustFetch, RateLimiter } from '../lib/crawler';

const limiter = new RateLimiter({ minDelayMs: 1000, addJitter: true });

const response = await robustFetch('https://api.example.com/data', {
  timeoutMs: 10000,
  retry: { maxRetries: 3 },
  rateLimiter: limiter,
});
```

### 2. é‡è¤‡é˜²æ­¢ãƒ˜ãƒ«ãƒ‘ãƒ¼

ç”Ÿãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨å•†å“ã¨ã®ç´ä»˜ã‘ã‚’ç®¡ç†ï¼š

```typescript
import {
  checkDugaRawData,
  upsertDugaRawData,
  linkProductToRawData,
  markRawDataAsProcessed,
  calculateJsonHash,
} from '../lib/crawler';

// APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—
const apiResponse = await fetchDugaApi(productId);

// 1. é‡è¤‡ãƒã‚§ãƒƒã‚¯
const check = await checkDugaRawData(productId, apiResponse);

if (check.exists && !check.hasChanged) {
  // ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›´ãªã—ã€ã‚¹ã‚­ãƒƒãƒ—
  console.log('No changes detected, skipping...');
  return;
}

// 2. ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜/æ›´æ–°
const { id: rawDataId, isNew } = await upsertDugaRawData(
  productId,
  apiResponse,
  check.newHash
);

// 3. productsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
const productId = await saveToProducts(apiResponse);

// 4. ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨productsã‚’ãƒªãƒ³ã‚¯
const link = await linkProductToRawData(
  productId,
  'duga',
  rawDataId,
  'duga_raw_responses',
  check.newHash
);

if (link.needsReprocessing) {
  // ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€å†å‡¦ç†ãŒå¿…è¦
  await reprocessProduct(productId);
}

// 5. å‡¦ç†å®Œäº†ã‚’ãƒãƒ¼ã‚¯
await markRawDataAsProcessed('duga', rawDataId);
```

### 3. AIæ©Ÿèƒ½

```typescript
import { CrawlerAIHelper, processProductWithAI } from '../lib/crawler';

// ã‚·ãƒ³ãƒ—ãƒ«ãªä½¿ã„æ–¹
const result = await processProductWithAI({
  title: 'ä½œå“ã‚¿ã‚¤ãƒˆãƒ«',
  description: 'ä½œå“èª¬æ˜',
  performers: ['å‡ºæ¼”è€…A'],
  genres: ['ã‚¸ãƒ£ãƒ³ãƒ«1', 'ã‚¸ãƒ£ãƒ³ãƒ«2'],
});

console.log(result.tags);        // { genres: [...], attributes: [...], ... }
console.log(result.translations); // { en: {...}, zh: {...}, ko: {...} }

// ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã£ãŸè©³ç´°ãªåˆ¶å¾¡
const aiHelper = new CrawlerAIHelper();

// ã‚¿ã‚°æŠ½å‡ºã®ã¿
const tags = await aiHelper.extractTags('ä½œå“ã‚¿ã‚¤ãƒˆãƒ«', 'èª¬æ˜');

// ç¿»è¨³ã®ã¿
const translations = await aiHelper.translate('ã‚¿ã‚¤ãƒˆãƒ«', 'èª¬æ˜');

// ä¸€æ‹¬å‡¦ç†
const results = await aiHelper.processProducts(products, {
  extractTags: true,
  translate: true,
  generateDescription: false,
}, 500); // 500msã®é…å»¶
```

### 4. ãƒ¬ãƒ¼ãƒˆåˆ¶é™

```typescript
import { RateLimiter, getRateLimiterForSite, SITE_RATE_LIMITS } from '../lib/crawler';

// ã‚µã‚¤ãƒˆåˆ¥ã®ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä½¿ç”¨
const limiter = getRateLimiterForSite('duga');

// ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
const customLimiter = new RateLimiter({
  minDelayMs: 2000,
  maxConcurrent: 3,
  addJitter: true,
  jitterRange: 500,
});

// ä½¿ç”¨æ–¹æ³•1: wait/done ãƒ‘ã‚¿ãƒ¼ãƒ³
await limiter.wait();
try {
  await fetch(url);
} finally {
  limiter.done();
}

// ä½¿ç”¨æ–¹æ³•2: execute ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ¨å¥¨ï¼‰
const result = await limiter.execute(async () => {
  return await fetch(url);
});
```

## é‡è¤‡é˜²æ­¢ã®ä»•çµ„ã¿

### ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«

| ãƒ†ãƒ¼ãƒ–ãƒ« | ç”¨é€” |
|---------|------|
| `duga_raw_responses` | DUGA APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ |
| `sokmil_raw_responses` | ã‚½ã‚¯ãƒŸãƒ«APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ |
| `mgs_raw_pages` | MGSã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœ |
| `raw_html_data` | æ±ç”¨HTMLãƒ‡ãƒ¼ã‚¿ï¼ˆDTI, FC2ç­‰ï¼‰ |
| `raw_csv_data` | CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ |

### product_raw_data_links

ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨productsã®é–¢ä¿‚ã‚’ç®¡ç†ï¼š

```sql
CREATE TABLE product_raw_data_links (
  id SERIAL PRIMARY KEY,
  product_id INTEGER REFERENCES products(id),
  source_type TEXT NOT NULL,      -- 'duga', 'sokmil', 'mgs', etc.
  raw_data_id INTEGER NOT NULL,
  raw_data_table TEXT NOT NULL,   -- å‚ç…§å…ˆãƒ†ãƒ¼ãƒ–ãƒ«å
  content_hash VARCHAR(64),       -- å‡¦ç†æ™‚ç‚¹ã®ãƒãƒƒã‚·ãƒ¥
  created_at TIMESTAMP DEFAULT NOW()
);
```

### é‡è¤‡æ¤œå‡ºãƒ•ãƒ­ãƒ¼

1. **ã‚¯ãƒ­ãƒ¼ãƒ«æ™‚**: å–å¾—ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
2. **æ—¢å­˜ãƒã‚§ãƒƒã‚¯**: æ—¢å­˜ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒƒã‚·ãƒ¥ã‚’æ¯”è¼ƒ
3. **å¤‰æ›´ãªã—**: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç„¡é§„ãªå‡¦ç†ã‚’å›é¿ï¼‰
4. **å¤‰æ›´ã‚ã‚Š**: ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã€å†å‡¦ç†ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
5. **ãƒªãƒ³ã‚¯æ›´æ–°**: `content_hash`ã‚’æ›´æ–°ã—ã¦å†å‡¦ç†æ¤œå‡ºå¯èƒ½ã«

## ãƒ­ã‚°å‡ºåŠ›

```typescript
import { crawlerLog } from '../lib/crawler';

crawlerLog.info('å‡¦ç†é–‹å§‹');
crawlerLog.success('å‡¦ç†å®Œäº†');
crawlerLog.warn('è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸');
crawlerLog.error('ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ');
crawlerLog.progress(50, 100, 'ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸'); // ğŸ“Š 50/100 (50%) - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
```

## ã‚µã‚¤ãƒˆåˆ¥ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®š

| ã‚µã‚¤ãƒˆ | æœ€å°é–“éš” | ã‚¸ãƒƒã‚¿ãƒ¼ |
|-------|---------|----------|
| DTI | 500ms | 300ms |
| DUGA | 1000ms | ãªã— |
| MGS | 2000ms | 500ms |
| FC2 | 3000ms | 1000ms |
| Japanska | 1500ms | 500ms |
| Sokmil | 1000ms | 300ms |
