# Crawler Dockerfile for Cloud Run Jobs
FROM node:20-slim

WORKDIR /app

# Install Chromium dependencies for Puppeteer
RUN apt-get update && apt-get install -y \
    chromium \
    fonts-ipafont-gothic \
    fonts-wqy-zenhei \
    fonts-thai-tlwg \
    fonts-kacst \
    fonts-freefont-ttf \
    libxss1 \
    --no-install-recommends \
    && rm -rf /var/lib/apt/lists/*

# Set Puppeteer environment variables
ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium

# Install dependencies
COPY package*.json ./
RUN npm ci

# Copy only necessary files
COPY lib ./lib
COPY tsconfig.json ./tsconfig.json

# Copy only necessary script files individually to avoid problematic files
RUN mkdir -p scripts/crawlers scripts/backfill
COPY scripts/run-crawler.ts ./scripts/
COPY scripts/normalize-performers.ts ./scripts/
COPY scripts/generate-performer-reviews.ts ./scripts/
COPY scripts/crawlers/ ./scripts/crawlers/
COPY scripts/backfill/ ./scripts/backfill/

# Set environment
ENV NODE_ENV=production

# Entry point for different crawler jobs
# Usage: docker run image CRAWLER_TYPE [options]
# CRAWLER_TYPE: mgs, caribbeancom, heyzo, etc.
ENTRYPOINT ["npx", "tsx", "scripts/run-crawler.ts"]
